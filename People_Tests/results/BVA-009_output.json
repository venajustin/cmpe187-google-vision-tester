{
  "test_case_id": "BVA-009",
  "test_name": "Count of 9 Pedestrians (Medium Group Max-1)",
  "category": "Boundary Value Analysis",
  "timestamp": "2025-10-12T18:13:24.438417",
  "test_configuration": {
    "expected_people_count": 9,
    "detection_threshold": 85,
    "group_size_category": "medium"
  },
  "description": "Count of 9 Pedestrians (Medium Group Max-1)",
  "expected_results": {
    "actual_people_in_scene": 9,
    "detection_rate_threshold": 85,
    "count_tolerance": 2,
    "group_size_category": "medium",
    "false_positives": 0,
    "false_negatives": 0
  },
  "actual_results": {
    "actual_people_in_scene": 9,
    "detected_people": 8,
    "detection_rate": 88.89,
    "count_error": 1,
    "count_within_tolerance": true,
    "false_positives": 0,
    "false_negatives": 1,
    "bounding_boxes_drawn": 8,
    "maximum_confidence": 0.7733
  },
  "detected_people_details": [
    {
      "person_id": 1,
      "name": "Person",
      "confidence": 0.7733,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.6562,
            "y": 0.5312
          },
          {
            "x": 0.7617,
            "y": 0.5312
          },
          {
            "x": 0.7617,
            "y": 0.7188
          },
          {
            "x": 0.6562,
            "y": 0.7188
          }
        ]
      }
    },
    {
      "person_id": 2,
      "name": "Person",
      "confidence": 0.7732,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.1934,
            "y": 0.5273
          },
          {
            "x": 0.3223,
            "y": 0.5273
          },
          {
            "x": 0.3223,
            "y": 0.7344
          },
          {
            "x": 0.1934,
            "y": 0.7344
          }
        ]
      }
    },
    {
      "person_id": 3,
      "name": "Person",
      "confidence": 0.7714,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.0427,
            "y": 0.5312
          },
          {
            "x": 0.1221,
            "y": 0.5312
          },
          {
            "x": 0.1221,
            "y": 0.7266
          },
          {
            "x": 0.0427,
            "y": 0.7266
          }
        ]
      }
    },
    {
      "person_id": 4,
      "name": "Person",
      "confidence": 0.769,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.5547,
            "y": 0.5391
          },
          {
            "x": 0.6406,
            "y": 0.5391
          },
          {
            "x": 0.6406,
            "y": 0.7344
          },
          {
            "x": 0.5547,
            "y": 0.7344
          }
        ]
      }
    },
    {
      "person_id": 5,
      "name": "Person",
      "confidence": 0.7663,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.3398,
            "y": 0.5273
          },
          {
            "x": 0.4492,
            "y": 0.5273
          },
          {
            "x": 0.4492,
            "y": 0.7266
          },
          {
            "x": 0.3398,
            "y": 0.7266
          }
        ]
      }
    },
    {
      "person_id": 6,
      "name": "Person",
      "confidence": 0.6835,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.3398,
            "y": 0.5273
          },
          {
            "x": 0.4492,
            "y": 0.5273
          },
          {
            "x": 0.4492,
            "y": 0.7266
          },
          {
            "x": 0.3398,
            "y": 0.7266
          }
        ]
      }
    },
    {
      "person_id": 7,
      "name": "Person",
      "confidence": 0.6607,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.0967,
            "y": 0.5234
          },
          {
            "x": 0.1748,
            "y": 0.5234
          },
          {
            "x": 0.1748,
            "y": 0.7344
          },
          {
            "x": 0.0967,
            "y": 0.7344
          }
        ]
      }
    },
    {
      "person_id": 8,
      "name": "Person",
      "confidence": 0.6172,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.4883,
            "y": 0.5312
          },
          {
            "x": 0.5625,
            "y": 0.5312
          },
          {
            "x": 0.5625,
            "y": 0.7266
          },
          {
            "x": 0.4883,
            "y": 0.7266
          }
        ]
      }
    }
  ],
  "test_result": {
    "status": "PASS",
    "meets_functional_requirements": true,
    "failure_reasons": [],
    "reason": "Test PASSED: Expected 9 people, detected 8 people. Detection rate: 88.9% (\u226585% required). Count error: 1 (within \u00b12 tolerance for medium groups). Meets functional requirements."
  },
  "output_files": {
    "result_image": "/Users/tanyareuben/Documents/Year 5/Fall 2025/CMPE 187/cmpe187-google-vision-tester/People_Tests/results/BVA-009_result.jpg",
    "output_json": "/Users/tanyareuben/Documents/Year 5/Fall 2025/CMPE 187/cmpe187-google-vision-tester/People_Tests/results/BVA-009_output.json"
  },
  "input_categories": {
    "environmental_conditions": "Daylight",
    "distance_range": "Close to Medium",
    "occlusion_level": "Moderate (crowd density)",
    "group_size": "Medium Group (9 people)"
  },
  "comparison": {
    "detection_rate_met": true,
    "count_within_tolerance": true,
    "expected_vs_actual_count": {
      "expected": 9,
      "actual": 8,
      "difference": 1,
      "exact_match": false
    },
    "criteria_checks": {
      "detection_rate": {
        "threshold": 85,
        "actual": 88.89,
        "passed": true
      },
      "count_accuracy": {
        "tolerance": 2,
        "error": 1,
        "passed": true
      }
    }
  },
  "timing": {
    "start_time": "2025-10-12 18:13:23",
    "end_time": "2025-10-12 18:13:24",
    "duration_seconds": 1.354,
    "duration_formatted": "1.35s"
  }
}