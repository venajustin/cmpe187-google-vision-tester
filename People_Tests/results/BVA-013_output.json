{
  "test_case_id": "BVA-013",
  "test_name": "Count of 19 Pedestrians (Large Group Max-1)",
  "category": "Boundary Value Analysis",
  "timestamp": "2025-10-12T21:06:46.013918",
  "test_configuration": {
    "expected_people_count": 19,
    "detection_threshold": 85,
    "group_size_category": "large"
  },
  "description": "Count of 19 Pedestrians (Large Group Max-1)",
  "expected_results": {
    "actual_people_in_scene": 19,
    "detection_rate_threshold": 85,
    "count_tolerance": 3,
    "group_size_category": "large",
    "false_positives": 0,
    "false_negatives": 0
  },
  "actual_results": {
    "actual_people_in_scene": 19,
    "detected_people": 7,
    "detection_rate": 36.84,
    "count_error": 12,
    "count_within_tolerance": false,
    "false_positives": 0,
    "false_negatives": 12,
    "bounding_boxes_drawn": 7,
    "maximum_confidence": 0.8658
  },
  "detected_people_details": [
    {
      "person_id": 1,
      "name": "Person",
      "confidence": 0.8658,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.0022,
            "y": 0.2061
          },
          {
            "x": 0.1348,
            "y": 0.2061
          },
          {
            "x": 0.1348,
            "y": 0.9258
          },
          {
            "x": 0.0022,
            "y": 0.9258
          }
        ]
      }
    },
    {
      "person_id": 2,
      "name": "Person",
      "confidence": 0.855,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.7812,
            "y": 0.1865
          },
          {
            "x": 0.9102,
            "y": 0.1865
          },
          {
            "x": 0.9102,
            "y": 0.8242
          },
          {
            "x": 0.7812,
            "y": 0.8242
          }
        ]
      }
    },
    {
      "person_id": 3,
      "name": "Person",
      "confidence": 0.8284,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.334,
            "y": 0.1797
          },
          {
            "x": 0.4629,
            "y": 0.1797
          },
          {
            "x": 0.4629,
            "y": 0.8516
          },
          {
            "x": 0.334,
            "y": 0.8516
          }
        ]
      }
    },
    {
      "person_id": 4,
      "name": "Person",
      "confidence": 0.8225,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.2314,
            "y": 0.2061
          },
          {
            "x": 0.3477,
            "y": 0.2061
          },
          {
            "x": 0.3477,
            "y": 0.8477
          },
          {
            "x": 0.2314,
            "y": 0.8477
          }
        ]
      }
    },
    {
      "person_id": 5,
      "name": "Person",
      "confidence": 0.8052,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.8867,
            "y": 0.1699
          },
          {
            "x": 0.9961,
            "y": 0.1699
          },
          {
            "x": 0.9961,
            "y": 0.8164
          },
          {
            "x": 0.8867,
            "y": 0.8164
          }
        ]
      }
    },
    {
      "person_id": 6,
      "name": "Person",
      "confidence": 0.7925,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.5234,
            "y": 0.168
          },
          {
            "x": 0.6328,
            "y": 0.168
          },
          {
            "x": 0.6328,
            "y": 0.8164
          },
          {
            "x": 0.5234,
            "y": 0.8164
          }
        ]
      }
    },
    {
      "person_id": 7,
      "name": "Person",
      "confidence": 0.7872,
      "bounding_box": {
        "normalized_vertices": [
          {
            "x": 0.1562,
            "y": 0.1152
          },
          {
            "x": 0.2832,
            "y": 0.1152
          },
          {
            "x": 0.2832,
            "y": 0.3379
          },
          {
            "x": 0.1562,
            "y": 0.3379
          }
        ]
      }
    }
  ],
  "test_result": {
    "status": "FAIL",
    "meets_functional_requirements": false,
    "failure_reasons": [
      "Detection rate 36.8% below 85% threshold",
      "Count error 12 exceeds \u00b13 tolerance"
    ],
    "reason": "Test FAILED: Expected 19 people, detected 7 people. Detection rate: 36.8% (<85% threshold). Count error: 12 (exceeds \u00b13 tolerance). Does not meet functional requirements."
  },
  "output_files": {
    "result_image": "/Users/tanyareuben/Documents/Year 5/Fall 2025/CMPE 187/cmpe187-google-vision-tester/People_Tests/results/BVA-013_result.jpg",
    "output_json": "/Users/tanyareuben/Documents/Year 5/Fall 2025/CMPE 187/cmpe187-google-vision-tester/People_Tests/results/BVA-013_output.json"
  },
  "input_categories": {
    "environmental_conditions": "Daylight",
    "distance_range": "Medium",
    "occlusion_level": "Heavy (significant occlusions)",
    "group_size": "Large Group (19 people)"
  },
  "comparison": {
    "detection_rate_met": false,
    "count_within_tolerance": false,
    "expected_vs_actual_count": {
      "expected": 19,
      "actual": 7,
      "difference": 12,
      "exact_match": false
    },
    "criteria_checks": {
      "detection_rate": {
        "threshold": 85,
        "actual": 36.84,
        "passed": false
      },
      "count_accuracy": {
        "tolerance": 3,
        "error": 12,
        "passed": false
      }
    }
  },
  "timing": {
    "start_time": "2025-10-12 21:06:44",
    "end_time": "2025-10-12 21:06:46",
    "duration_seconds": 1.458,
    "duration_formatted": "1.46s"
  }
}